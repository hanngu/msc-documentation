\section{Super Swarm Optimization}

The baseline of the proposed Super Swarm Optimization (SSO) algorithm is an implementation of the basic ACO algorithm introduced by \citet{nanda11} and described in chapter \ref{backgroundAndMotivation}. The basic ACO algorithm have some limitations[ref]. To overcome some of these known limitations, and to answer our research question \ref{itm:2a}) %(if is it efficient to combine attributes from different swarm intelligence algorithms to solve the vehicle routing problem,) 
Some additional features are given. The ants are given memory, and can remember whether or not it has visited a node in the creation of the route set, and some acknowledged features inspired by the PSO and BSO are implemented to the proposed SSO algorithm.

First, Inertia Weight (IW) from PSO is added to SSO. Inertia weight is a decreasing parameter brought to the PSO for balancing local and global search. In the early iterations of the algorithm, the particles tends to explore more, and becoming more organized and coordinated in the late iterations.  To do this in our algorithm we have implemented a feature called Crazy Ants (CA). A given amount of the ants to be generated become crazy. A CA does not select edges based on the edge value, but instead selects a random node for the next edge. The IW value is high in the beginning, denoting a higher amount of crazy ants, and when this value decreases (for each iteration), the amount of CA decreases. Second, the awareness of the global best solution is given the ants. In PSO each individual particle knows its best position so far, in addition to the best position achieved among all the particles. To implement this, the best ant's results is retained after each iteration. The edge of the current best ant is added to the probability for this edge to be selected again, and when ants are selecting next edges (given that it is not the first ant), the chance for this best edge to be selected becomes greater. What we hope to achieve with these features is overcoming the ACO limitation of getting stuck at a local optima.

Third, the so called \textit{following} feature from BSO is added to SSO. Deciding which bee to follow is considered to be a function of the quality of the food source to the recruiter. After the first run, some ants are initialized as ``uncommitted followers''. They follow the $n$ best ants from the previous iteration without. This feature is added to reward the edges in the final best route sets with a higher pheromone value, and with this, hopefully achieve better results concerning the performance criteria, introduced in section \ref{sec:performanceCriteria} on page \pageref{sec:performanceCriteria}. 


%%Artifacts:
%\begin{enumerate}
%\item The ants have memory. It can remember whether or not it has visited a node in the creation of the route set.
%\item The ants have a notion of the global best ant. The ant will favor the edge chosen by the global best ant. (PSO)
%\item The ants can be ``crazy''. A crazy ant chooses next nodes at random given possible nodes, not considering the edge %values. This is to compensate for ACO getting stuck at local optima.
%\item An inertia weight is used. The inertia weight is used to calculate the number of crazy ants. At the beginning the number of crazy ants is larger (exploring). The inertia weight is decreased by each iteration, and therefore the number of crazy ants is decreased (exploiting). PSO.  \emph{\color{red} Check if inertia weight is mentioned in the PSO-section. If not write about it and refer to http://www.softcomputing.net/nabic11_7.pdf}
%\item After the first run, some ants are initialized as ``uncommitted followers''. They follow the $n$ best ants from the previous iteration without doubt. (BCO)
%\end{enumerate}



