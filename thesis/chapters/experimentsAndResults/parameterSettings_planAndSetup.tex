\section{Parameter Settings}
\label{sec:parametersettings}

\subsection{Experimental Plan}
Metaheuristics, like ACO, requires good initial parameters to solve concrete problems optimally. The parameter settings experiment will study the effect of the variation of the parameters, and will be conducted to find the most optimal algorithm parameters. As mentioned in Section \vref{sec:relatedWork}, refers several authors to their parameter settings experiments as a product of ``trial and error'', without presenting the parameter values tested. For contributing to the field and providing a starting point for future research, will this thesis include a complete review of the conducted experiment. %The selected values for the parameters will be used as the default values in the performance comparison experiments. 
In addition will studying the effect of the additional parameters inspired by PSO and BCO help establish whether these attributes improves the basic ACO algorithm (Research Question \vref{itm:2a}).

\subsection{Experimental Setup}
\label{subsec:parameterSettings_setup}
The parameters of the proposed algorithm are described in Section \vref{sec:algoInitialization}, and the parameters 
to be tested with different values are shown in Table \ref{table:parameters}. The value of the inertia weight, $IW$, is sat to 1.0 and will not be tested with different candidate values. This is because $IW$ directly affects $CA$ (as described in Section \vref{sec:algoGeneratingSuperSwarm}) and because an implementation of different inertia weight strategies is beyond the scope of this thesis. The value of $p_v$, which is the constant added to each edge each time it is visited by an ant, is sat to 0.1. $p_v$ will neither be tested with different values. This is because the edge selection phase, as described in Section \vref{sec:selectingNextNode}, is influenced by the ratio of the edge's pheromone level and the summed pheromone level of all possible edges. The value of $p_v$ could therefore, in fact, be any positive real number as long as the value is constant.

Each parameter shown in Table \ref{table:parameters} are tested with minimum \textit{four} different values, in order to establish which value for each parameter that resulted in the lowest total fitness $TOTFIT$. The reader recalls from Section \vref{sec:algoEvaluation} that the lower the $TOTFIT$, the better the solution. 

The selected default value and the selected candidate values for parameter $s$ and $i$ are inspired by the corresponding values described in related research\citep{salehi-nezhad07, poorzahedy11, sedighpour14, kechagiopoulos14}.

The parameter $E$, $AF$, and $CA$ are considered unique for the proposed algorithm, and their default values are chosen based on preliminary testing not included in this thesis. Even though ACO usually consists of a evaporation parameter, $E$ is unique for this research because $E$ is stated as a percentage, and not as a constant or a function. 
Because $E$, $AF$, and $CA$ all are stated as percentages, they will be tested with values in the range from 0\% to 100\%. %To determine the effect of the additional BCO and PSO features by removing them from the implementation, will parameters $AF$ and $CA$ also be tested with value 0 and 1.0.

The idea of the parameter $p_b$ is to test whether ``rewarding'' edges in the best route sets, by adding more pheromone to edges walked by the Following Ants, will boost the algorithms performance. The reader recalls from Section \vref{sec:algoGeneratingSuperSwarm} that the number $n$ of following ants are determined by the $AF$ percentage of the best ants to be followed from the previous iteration. The default value of $p_b$ will be 0.0, which leads to no extra pheromone added to the edges walked the Following Ants. Because the amount of extra pheromone granted each edge is dependent of both $p_b$ and $AF$, these two parameters are correlated. Because of this the candidate values of $p_b$ will be tested using the selected value of $AF$, and not the default value of $AF$. The value of $p_b$ must be seen in context with the value of parameter $p_v$ which is sat to 0.1, and because of this the candidate values of $p_b$ will be in the range of 0.0 to 1.3.\emph{\color{blue} Skrive hvorfor verdiene er mellom 0.0 og 1.3}.  

The default values for each parameter can be found in Table \ref{table:parameters}, and the chosen candidate values can be found in Table \vref{table:parameterSettings2}.

\begin{table}[H]
	\small
	\begin{tabular}{|l|l|l|}
    	\hline
    	Parameter & Description & Default Value\\
    	\hline
    	$s$ & The SuperSwarm Colony Size & 50\\
    	$i$ & The numbers of iterations (which is the stop criteria) & 50\\
    	$E$ & The percentage of pheromones to evaporate at each iteration & 10\%\\
    	$CA$ & The probability that a given ant is declared ``crazy'' & 10\%\\
    	$AF$ & The percentage of ants to be followed & 10\%\\
        $p_b$ & The pheromone constant added to edges walked by following ants & 0.0\\
   	    \hline
    \end{tabular}
    \caption {Candidate Parameters with their Default Values}
    \label{table:parameters}
\end{table}

For each candidate value of the parameters $s$, $i$, $E$, and $p_b$ the algorithm will be run 30 times.  For the candidate values of the parameters $AF$ and $CA$, the algorithm will be run 50 times for each value. 
The values of $CA$ and $AF$ are ran more times than the other parameters, because the result of these may help determine Research Question \vref{itm:2a}. By running the algorithm with additional runs, the margin of error will hopefully decrease and the results will thus be more correct.

For all candidate values, the average, best, and worst $TOTFIT$ value will be presented, as well as the margin of error calculated with at confidence level at 95\%, and the standard deviation. For each parameter the value that resulted in the lowest average $TOTFIT$ is chosen. 

The performed experiments regarding Parameter Settings will all be run Ubuntu instances provided by the Google Cloud Platform. The instances used will be of the type n1-highcpu-2, which contains two 2.6GHz Intel Xeon E5 (Sandy Bridge) virtual CPUs and 1.8 GB memory\cite{website:google}.  
%In addition will $p_b$ run with the new value of $AF$.

%This is due to the the central limit theorem[Ref - Statistiske Metoder A.Hald p.139], which states that the sampling distribution of any statistic will be normal or nearly normal, if the sample size is large enough, and many statisticians say that a sample size of 30 is large enough.
