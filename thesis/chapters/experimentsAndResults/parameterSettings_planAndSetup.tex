\subsection{Parameter Settings}
\label{subsec:parameterSettings_setup}
Each candidate parameter, Table \vref{table:parameters}, is assigned a default value to be held constant while the other parameters are tested with minimum \textit{four} different candidate values. 

The default value and candidate values for $s$ and $i$ are inspired by the corresponding values described in related research\citep{salehi-nezhad07}, \citep{poorzahedy11}, \citep{sedighpour14}, \citep{kechagiopoulos14}.

Parameters $E$, $AF$, and $CA$ are all unique for the proposed algorithm, and their default values are chosen based on preliminary testing not included in this thesis. Their values are stated as a percentage and will be tested with candidate values in the range from 0\% to 100\%. %To determine the effect of the additional BCO and PSO features by removing them from the implementation, will parameters $AF$ and $CA$ also be tested with value 0 and 1.0.

The idea of the parameter $p_b$ is to test whether ``rewarding'' edges in the best route sets, by adding more pheromone to edges walked by $AF$, will boost the algorithms performance. Its default value will be 0.0. Since it's value is dependent on the amount of $AF$, it will be tested against two parameter values of $AF$. It is worth mentioning that $p_ b$ is strongly dependent on the value of parameter $p_v$ (the pheromone constant used to determine how much pheromone to be added to all visited edges). Different values of $p_v$ will not be tested, because the edge selection phase is only determent by the ratio of the edge's pheromone level and the summed pheromone level on all the edges. The value of $p_v$ could, in fact, be any real number as long as the value is constant, and is therefore sat to 0.1. The candidate values for $p_b$ will be kept equal to, or greater than $p_v$, and will be tested in the range from 0 to 1.3. 

The value of the inertia weight, $IW$, is sat to 1.0 and will not be tested with different candidate values. This is because $IW$ directly affects $CA$ (as described in Section \vref{sec:algoGeneratingSuperSwarm}) and because an implementation of different inertia weight strategies is beyond the scope of this thesis. 

The default values for each parameter can be found in Table \vref{table:parameters}, and the chosen candidate values can be found in Table \vref{table:parameterSettings2}.

\begin{table}[H]
	\small
	\begin{tabular}{|l|l|l|}
    	\hline
    	Parameter & Description & Default Value\\
    	\hline
    	$s$ & The SuperSwarm Colony Size & 50\\
    	$i$ & The numbers of iterations (which is the stop criteria) & 50\\
    	$E$ & The percentage of pheromones to evaporate at each iteration & 10\%\\
    	$CA$ & The probability that a given ant is declared ``crazy'' & 10\%\\
    	%$BR$ & The percentage of route sets to be granted extra pheromone & 10\%\\
    	$AF$ & The percentage of ants to be followed & 10\%\\
        $p_b$ & The pheromone constant added to edges walked by following ants & 0.0\\
   	    \hline
    \end{tabular}
    \caption {Candidate Parameters with their Default Values}
    \label{table:parameters}
\end{table}

For each candidate value of the parameters $s$, $i$, $E$, and $p_b$ the algorithm will be run 30 times.  For the candidate values of the parameters $AF$ and $CA$, the algorithm will be run 50 times for each value. Their results will help determine Research Question \vref{itm:2a}, and by running the algorithm with additional runs, the margin of error will hopefully increase.

For all candidate values, the average, best, and worst $TOTFIT$ value will be presented, as well as the margin of error (confidence interval level 95), and the standard deviation. 
%In addition will $p_b$ run with the new value of $AF$.

%This is due to the the central limit theorem[Ref - Statistiske Metoder A.Hald p.139], which states that the sampling distribution of any statistic will be normal or nearly normal, if the sample size is large enough, and many statisticians say that a sample size of 30 is large enough.
The parameter values selected will be the one with the lowest average $TOTFIT$. As mentioned in \vref{sec:algoEvaluation}, the lower the $TOTFIT$, the better the solution. 
