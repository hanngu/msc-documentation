\section{Discussion}
\begin{itemize}
\item[Goal:]  Increase the number of public transportation passengers by making urban transit networks more efficient.
\end{itemize}
%Research Question \vref{itm:1} as a whole and Research Question \vref{itm:3a} is answered in Chapter \vref{relatedWork}.

\begin{itemize}
\item[\textbf{(2) a)}] Does adding attributes from other swarm intelligence-methods improve the performance of the standard ant colony optimization algorithm?
\end{itemize}

First of all, it is important to acknowledge that ACO has many advantages in solving VRPs. Solving certain types of NP-hard problems in polynomial time, and being optimal given there is no absolutely correct solution are some of these advantages. As demonstrated in Section \vref{subsec:evaluating_PerfomanceComparison}, before any distinct pheromone trail is laid, the ant's choices are more random and thus they perform a broad search in the environment. This randomness will decrease over time as the pheromone trails become more distinct. Because pheromone evaporate over time, shorter paths will be favored over longer paths simply because shortest paths takes shorter time. The next ants follow the trails with the most pheromone, giving these shorter paths even more pheromone. 

%In the natural world, ants (initially) wander randomly, and upon finding food return to their colony while laying down pheromone trails. If other ants find such a path, they are likely not to keep travelling at random, but to instead follow the trail, returning and reinforcing it if they eventually find food (see Ant communication). % Over time, however, the pheromone trail starts to evaporate, thus reducing its attractive strength. The more time it takes for an ant to travel down the path and back again, the more time the pheromones have to evaporate. A short path, by comparison, gets marched over more frequently, and thus the pheromone density becomes higher on shorter paths than longer ones. Pheromone evaporation also has the advantage of avoiding the convergence to a locally optimal solution. If there were no evaporation at all, the paths chosen by the first ants would tend to be excessively attractive to the following ones. In that case, the exploration of the solution space would be constrained. %Thus, when one ant finds a good (i.e., short) path from the colony to a food source, other ants are more likely to follow that path, and positive feedback eventually leads to all the ants' following a single path. The idea of the ant colony algorithm is to mimic this behavior with "simulated ants" walking around the graph representing the problem to solve.

This solution is good when the problem to be solved is to \emph{\color{blue} finne noe her}. However, in the UTRP problem, there are many factors for determining a good route set. As mentioned, a good route set is the one with the best results concerning the performance criteria. The evaluation of the route set as a whole is done after each iteration, and this evaluation will determine how good the produced route set is. Because standard ACO doesn't \emph{\color{blue} finne noe her}. there will be no possibility to ``inform'' the ants if they are converging towards a local optimum. To overcome these weaknesses of ACO and to boost the algorithms performance, attributes inspired by other approaches within swarm intelligence methods was added the proposed algorithm. 

In the bee colony optimization (BCO), the idea is to apply collective intelligence to the optimization process. When the artificial bee has produced a good route set it can ``recruit'' other nest-mates, and thus inform the others that a good route set is found. This process inspired to add the ``following'' feature to the proposed method. After the route sets are evaluated, an amount of the best ants with the best route sets is selected to be followed in the next iteration. The same amount of ants will follow the same routes as the one they are following, and thus create the exact same route set. This will give the edges in the best route sets more pheromone, and thus distinct edges with much pheromone (because they are walked by many ants, given the short path) from edges that are better concerning the performance criteria. The proposed algorithm's performance was improved with this additional attribute. However, the algorithm performed best with a relatively small amount of followers. Rewarding edges in a large amount best route sets will result in over appreciating too many edges, which again will unable to distinct edges in good route sets from edges in the best route sets. Thats why rewarding the edges in the best route sets with extra pheromone improved the performance further. However, \emph{\color{blue} inn med løsninger som har gjort det samme}.
%ACS: The offline pheromone update, similarly to MMAS, is applied at the end of each iteration by only one ant, which can be either the iteration-best or the best-so-far.

 %By making ants follow new best routes after each iteration will also give a variation of the best produced route sets, and thus avoid over rewarding edges in a local optima. 

% bra setning : and it can converge towards a (less optimal) solution. 

%With this additional attribute, information of the best known solution is still not known to the ants. Best route sets frequently produced and thus given additional pheromone may still not be the best known solution. In the particle swarm optimization (PSO) each particle's movement is influenced by its local best known position, and is guided toward the best known positions in the search-space, which are updated as better positions are found by other particles. An additional attribute, the notion of the global best solution so far is therefore added to the proposed method. This gives edges walked in the best known solution a higher probability of being selected. \emph{\color{blue} And thus. TODO, vente på resultater.}
In particle swarm optimization (PSO), like ACO, the particles tend to explore more in the the early iterations of the algorithm, and becoming more organized and coordinated at the late iterations. In PSO, this is due to a parameter called Inertia Weight. The parameter is added to balance the local and global search, preventing the particles from drastically changing directions. However, the best global known solution the particles are drawn against may, similar to ACO and BCO, be a (possible) local optima. An attribute called ``crazy ants'' is added to the proposed method, where an amount of the colony is given the possibility to explore edges completely random. Making decisions based on random choices will not be influenced by the best known solutions, which may be a local optima. This additional feature improved the performance of the proposed algorithm. This may be due to the fact that the attribute enables an amount of ants to explore undetected better solutions when pheromone trails becomes too great. The Inertia Weight parameter, inspired from PSO, denotes the amount of crazy ants in the beginning of each run, and the amount of ``crazy ants'' decrease in line with the parameter. Decreasing the inertia weight in PSO may suffer from low global search ability at the end of the run, and thus the possibly of getting stuck at a local optima. However, in the proposed method the ``crazy ants'' are not searching towards the best known solution, and will thus prevent the same disadvantage. 

%As mentioned in Section \vref{subsec:evaluating_PerfomanceComparison}, we can not unambiguously conclude that the additional attributes inspired by BCO and / or PSO was the only reason the performance of ACO improved. Giving the ants memory, inspired by \citet{dorigo96}, has previously proven to be effective concerning the performance of ACO. 

\begin{itemize}
\item[\textbf{(2) b)}] How does the proposed method perform compared to methods published in literature?
%\item[\textbf{(2) b?)}] Does the proposed method demonstrate good performance?
\end{itemize}

The proposed method produce the best average travel time compared to all route sets sizes published in the literature. Concerning the unsatisfied passengers criteria, there are no passengers needing to transfer more than twice in the best produced route set, which is equal to all approaches published in the literature. For the rest of the performance criteria concerning the number of direct travelers, one transfers, and two transfers, the algorithm performs below average compared to the other approaches. This is due to a user-defined parameter sat to favor a small travel time over a high amount of direct transfers, based on the ration between the two. Again, it is worth mentioning that a direct route is still an important factor when evaluating the best route set. This reflects that the number of direct travelers in the best produced route set is still relatively high.

As mentioned in the motivation, citizens often prefer private transportation because of the decreased travel time when no detours is needed. Then again, another important issue concerning passenger satisfiability, is the issue of not needing to change vehicles during a trip. Whether a passenger would travel travel direct with a larger travel time versus transferring and thus decrease the travel time, is a matter of preferences. As you can see in all the approaches published in the literature including the proposed algorithm, you will have to choose one at the expense of the other. One can argue back and forth on the importance of each criteria. We believe that in the modern urban city, a minimum travel time is an important factor. People should have a small travel time as an option if time is limited. As mentioned, the produced route network also possess a relatively high amount of direct routes, giving passengers opportunities to choose direct routes if this is desired. %And reflecting the average travel time of the best route set produced by the proposed algorithm, the direct travels are not very long. %jeg er litt usikker på om jeg er på villspor her
When all comes to all, it is eventually up to each individual passenger choosing what is most convenient for them. 


