\section{Discussion}
\begin{itemize}
\item[Goal:]  Increase the number of public transportation passengers by making urban transit networks more efficient.
\end{itemize}
Research Question \vref{itm:1} as a whole and Research Question \vref{itm:3a} is answered in Chapter \vref{relatedWork}.
%\subsection{Does adding attributes from other swarm intelligence-methods improve the performance of the standard ant colony optimization algorithm?}

\begin{itemize}
\item[\textbf{(2) a)}] Does adding attributes from other swarm intelligence-methods improve the performance of the standard ant colony optimization algorithm?
\end{itemize}

First of all, it is important to acknowledge that ACO has many advantages in solving VRPs. Solving certain types of NP-hard problems in polynomial time, and being optimal given there is no absolutely correct solution are some of these advantages. As demonstrated in Section \vref{subsec:evaluating_PerfomanceComparison}, before  any distinct pheromone trail is laid, the ant's choices are more random and thus they perform a broad search in the environment. This randomness will decrease over time as the pheromone trails become more distinct. Because pheromone evaporate over time, shorter paths will be favored over longer paths simply because shortest paths takes shorter time. The next ants follow the trails with the most pheromone, giving these shorter paths even more pheromone. This solution is good when the problem to be solved is to find the shortest possible route set. However, in the UTRP problem, there are many factors for determining a good route set. As mentioned, a good route set is the one with the best results concerning the performance criteria. The evaluation of the route set as a whole is done after each iteration, and this evaluation will determine if the route set actually is a good route set. Because ACO doesn't reward good route sets as a whole, there will be no possibility to ``inform'' the ants that they possibly not are walking towards the global optimal solution. To overcome these weaknesses of ACO, other approaches within swarm intelligence methods gave inspiration to additional attributes. 

In the bee colony optimization (BCO), the idea is to apply collective intelligence to the optimization process. When the artificial bee has produced a good route set it can recruit other ``nestmates'', and thus inform others that a good route set is found. This process inspired to add the ``following'' feature to the proposed method. After the route sets are evaluated, an amount of the best ants with the best route sets is selected to be followed in the next iteration. The same amount of ants will follow the same routes as the one they are following, and thus create the exact same route set. This will give the edges in the best route sets more pheromone, and thus distinct edges with much pheromone (because they are walked by many ants, given the short path) from edges that are better concerning the performance criteria. The algorithm's performance improved with this additional attribute. However, the algorithm performed best with a relatively small amount of followers. Rewarding edges in a large amount best route sets will result in over appreciating too many edges, which again will unable to distinct edges in good route sets from edges in the best route sets. Thats why rewarding the edges in the best route sets with extra pheromone improved the performance further.  %By making ants follow new best routes after each iteration will also give a variation of the best produced route sets, and thus avoid over rewarding edges in a local optima. 

%and it can converge towards a (less optimal) solution. 

With this additional feature, the ants will still not have the information of the best known solution. The best route sets that are made a lot and thus given more pheromone may still not be the best known solution. In the particle swarm optimization (PSO) each particle's movement is influenced by its local best known position, and is guided toward the best known positions in the search-space, which are updated as better positions are found by other particles. An additional attribute, the notion of the best known solution is therefore added to the proposed method. This gives edges walked in the best known solution a higher probability of being selected. \emph{\color{blue} And thus. TODO, vente p√• resultater.}

In PSO, the particles also tend to explore more in the the early iterations of the algorithm, and becoming more organized and coordinated at the late iterations. This is due to the parameter called the Inertia Weight. This parameter decreases after each iteration, preventing the particles from drastically changing directions. However, the best known solution the particles are drawn against may, similar to ACO and BSO, not be the global best solution. Therefore, an attribute called ``crazy ants'' was added to the proposed method. This attribute  will give an amount of the colony the possibility to explore edges completely random. Making decisions based on random choices will not be influenced by the best known solution which may be a possible local optima. And enables the ants to explore undetected better solutions, when the pheromone trail becomes too great on routes. Inertia Weight inspired by PSO was added to balancing local and global search. The parameter denotes the amount of crazy ants in the beginning of each run, and the amount of ants exploring random decrease in line with the parameter. Managing, as PSO, to act more random at early iterations and becoming more organized in the later iterations. In PSO, because decreasing the intertia weight , PSO may suffer from low global search ability at the end of the run, and thus getting stuck at a local optimum. However, in the proposed algorithm the crazy ants are not working towards the best known solution, and this will prevent this inconvinience in the proposed algorithm.

%Improving ACO, was first done by \citet{dorigo96}, where additional characteristics including memory was added.The addition of these features is typically done to increase the performance of the algorithm. This attribute was also added to the proposed algorithm. As we observed in Section \vref{subsec:evaluating_PerfomanceComparison} the SSO performs better already after the first iteration. This leads to us not being able to unambiguously conclude that the features added inspired by BCO and / or PSO was the only reason ACO was improved.

%However, based on the experimental results produced by the proposed algorithm, the additional features inspired by BCO and PSO improved the algorithm further %(and here was also the memory feature added). These results, shows that the performance of the proposed algorithm improved.

%The memory feature was also added to the proposed algorithm. We have observed that by adding this feature the ants were more capable of creating route sets that together corresponded to a connected graph and by not able passengers to travel between every two nodes in the network using a given route set. The reader recall from Section \vref{sec:algoRemoval} that if the route set generated by a given ant does not fulfill this constraint, the route set will neither be evaluated. Because removal of the memory feature decreases the number of ants to be evaluated, so does the probability of finding the very best route set. This leads to us not being able to unambiguously conclude that the features added from BCO and/or PSO improved the standard ACO algorithm.

    
%* As seen in the ACO vs SSO performance comparison one can see that SSO performs overall better than a plain ACO implementation. But as mentioned in the evaluation. ACO does not possess the memory feature. Which enables the ants to remember which node it has visited within the same route set. This feature makes it possible for the ants to create more route sets that are connected, this is important, because a passenger should be able to travel from every node to every other node withing the route network. This results in a lot of ACOs route sets will be discarded, and therefore not taken into evaluation. This means ACO will have less good route sets to be evaluated, and therefore increases the chance of finding the optimal route set. 


\begin{itemize}
\item[\textbf{(2) b)}] How does the proposed method perform compared to methods published in literature?
\end{itemize}
* As stated in Evaluation, the proposed algorithm produce the best average travel time, compared to all the published literature this algorithm is compared to. It performs best concerning the average travel time, regardless of the route set size, on the Mandl network. 

* The rest of the performance criteria, concerning the number of transfers - the algorithm performs just below average compared to the other approaches. 

* Again, is it worth mentioning that a direct route is still an important factor when selecting the best route set. But, this approach sat to favor a small average travel time.

* This is because:

* Whether a passenger would travel a little longer and travel direct, versus changing a route once and decrease the travel time is a matter of preferences. And as one can see, you have to choose one at the expense of the other. But, as mentioned in the motivation, citizens often prefer private transportation because of the decreased travel time. 
