\section{Discussion}
\begin{itemize}
\item[Goal:]  Increase the number of public transportation passengers by making urban transit networks more efficient.
\end{itemize}
Research Question \vref{itm:1} as a whole and Research Question \vref{itm:3a} is answered in Chapter \vref{relatedWork}.
%\subsection{Does adding attributes from other swarm intelligence-methods improve the performance of the standard ant colony optimization algorithm?}

\begin{itemize}
\item[\textbf{(2) a)}] Does adding attributes from other swarm intelligence-methods improve the performance of the standard ant colony optimization algorithm?
\end{itemize}

First of all, it is important to acknowledge that ACO has many advantages in solving VRPs. Solving certain types of NP-hard problems in polynomial time, and being optimal given there is no absolutely correct solution are some of these advantages. As demonstrated in Section \vref{subsec:evaluating_PerfomanceComparison}, before any distinct pheromone trail is laid, the ant's choices are more random and thus they perform a broad search in the environment. This randomness will decrease over time as the pheromone trails become more distinct. Because pheromone evaporate over time, shorter paths will be favored over longer paths simply because shortest paths takes shorter time. The next ants follow the trails with the most pheromone, giving these shorter paths even more pheromone. This solution is good when the problem to be solved is to find the shortest possible route set. However, in the UTRP problem, there are many factors for determining a good route set. As mentioned, a good route set is the one with the best results concerning the performance criteria. The evaluation of the route set as a whole is done after each iteration, and this evaluation will determine if the route set produced actually is a good route set. Because ACO doesn't reward good route sets as a whole, there will be no possibility to ``inform'' the ants if they are walking towards a local optimum. To overcome these weaknesses of ACO and to boost the algorithms performance, attributes inspired by other approaches within swarm intelligence methods was added the proposed algorithm. 

In the bee colony optimization (BCO), the idea is to apply collective intelligence to the optimization process. When the artificial bee has produced a good route set it can ``recruit'' other nest-mates, and thus inform the others that a good route set is found. This process inspired to add the ``following'' feature to the proposed method. After the route sets are evaluated, an amount of the best ants with the best route sets is selected to be followed in the next iteration. The same amount of ants will follow the same routes as the one they are following, and thus create the exact same route set. This will give the edges in the best route sets more pheromone, and thus distinct edges with much pheromone (because they are walked by many ants, given the short path) from edges that are better concerning the performance criteria. The proposed algorithm's performance was improved with this additional attribute. However, the algorithm performed best with a relatively small amount of followers. Rewarding edges in a large amount best route sets will result in over appreciating too many edges, which again will unable to distinct edges in good route sets from edges in the best route sets. Thats why rewarding the edges in the best route sets with extra pheromone improved the performance further.  %By making ants follow new best routes after each iteration will also give a variation of the best produced route sets, and thus avoid over rewarding edges in a local optima. 

%and it can converge towards a (less optimal) solution. 

With this additional attribute, information of the best known solution is still not known to the ants. Best route sets frequently produced and thus given additional pheromone may still not be the best known solution. In the particle swarm optimization (PSO) each particle's movement is influenced by its local best known position, and is guided toward the best known positions in the search-space, which are updated as better positions are found by other particles. An additional attribute, the notion of the global best solution so far is therefore added to the proposed method. This gives edges walked in the best known solution a higher probability of being selected. \emph{\color{blue} And thus. TODO, vente p√• resultater.}

Like ACO, the particles in PSO also tend to explore more in the the early iterations of the algorithm, and becoming more organized and coordinated at the late iterations. In PSO, this is due to a parameter called  Inertia Weight. This parameter decreases after each iteration, preventing the particles from drastically changing directions. However, the best known solution the particles are drawn against may, similar to ACO and BCO, be a local optimum. An attribute called ``crazy ants'' is added to the proposed method. This additional feature improved the performance of the proposed algorithm. An amount of the colony is given the possibility to explore edges completely random. Making decisions based on random choices will not be influenced by neither good solutions nor the best known solution (which again may be a possible local optima). The attribute enables some of the ants to explore undetected better solutions when pheromone trails becomes too great. Inertia Weight inspired by PSO was added to balance the local and global search. The parameter denotes the amount of crazy ants in the beginning of each run, and the amount of ``crazy ants'' decrease in line with the parameter. This manage the algorithm, as PSO, to act more random at the early iterations and becoming more organized in the later iterations. Decreasing the inertia weight in PSO may suffer from low global search ability at the end of the run, and thus the possibly of getting stuck at a local optimum. However, in the proposed method the crazy ants are not searching towards the best known solution, and will thus prevent the same disadvantage.

As mentioned in Section \vref{subsec:evaluating_PerfomanceComparison}, we can not unambiguously conclude that the additional attributes inspired by BCO and / or PSO was the only reason the performance of ACO improved. Giving the ants memory, inspired by \citet{dorigo96}, has previously proven to be effective concerning the performance of ACO. However, the individual tests on the additional parameters all improved the ACO performance further. All the above makes it therefore reasonable to conclude that adding attributes from other swarm intelligence-methods improve the performance of the standard ant colony optimization algorithm.

%Improving ACO, was first done by \citet{dorigo96}, where additional characteristics including memory was added.The addition of these features is typically done to increase the performance of the algorithm. This attribute was also added to the proposed algorithm. As we observed in Section \vref{subsec:evaluating_PerfomanceComparison} the SSO performs better already after the first iteration. This leads to us not being able to unambiguously conclude that the features added inspired by BCO and / or PSO was the only reason ACO was improved.

%However, based on the experimental results produced by the proposed algorithm, the additional features inspired by BCO and PSO improved the algorithm further %(and here was also the memory feature added). These results, shows that the performance of the proposed algorithm improved.

%The memory feature was also added to the proposed algorithm. We have observed that by adding this feature the ants were more capable of creating route sets that together corresponded to a connected graph and by not able passengers to travel between every two nodes in the network using a given route set. The reader recall from Section \vref{sec:algoRemoval} that if the route set generated by a given ant does not fulfill this constraint, the route set will neither be evaluated. Because removal of the memory feature decreases the number of ants to be evaluated, so does the probability of finding the very best route set. This leads to us not being able to unambiguously conclude that the features added from BCO and/or PSO improved the standard ACO algorithm.

    
%* As seen in the ACO vs SSO performance comparison one can see that SSO performs overall better than a plain ACO implementation. But as mentioned in the evaluation. ACO does not possess the memory feature. Which enables the ants to remember which node it has visited within the same route set. This feature makes it possible for the ants to create more route sets that are connected, this is important, because a passenger should be able to travel from every node to every other node withing the route network. This results in a lot of ACOs route sets will be discarded, and therefore not taken into evaluation. This means ACO will have less good route sets to be evaluated, and therefore increases the chance of finding the optimal route set. 


\begin{itemize}
\item[\textbf{(2) b)}] How does the proposed method perform compared to methods published in literature?
\end{itemize}
* As stated in Evaluation, the proposed algorithm produce the best average travel time, compared to all the published literature this algorithm is compared to. It performs best concerning the average travel time, regardless of the route set size, on the Mandl network. 

* The rest of the performance criteria, concerning the number of transfers - the algorithm performs just below average compared to the other approaches. 

* Again, is it worth mentioning that a direct route is still an important factor when selecting the best route set. But, this approach sat to favor a small average travel time.

* This is because:

* Whether a passenger would travel a little longer and travel direct, versus changing a route once and decrease the travel time is a matter of preferences. And as one can see, you have to choose one at the expense of the other. But, as mentioned in the motivation, citizens often prefer private transportation because of the decreased travel time. 
